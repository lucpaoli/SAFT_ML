{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/SAFT_ML`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.activate(\".\")\n",
    "using Clapeyron\n",
    "includet(\"./saftvrmienn.jl\")\n",
    "# These are functions we're going to overload for SAFTVRMieNN\n",
    "import Clapeyron: a_res, saturation_pressure, pressure\n",
    "\n",
    "using Flux\n",
    "using Plots, Statistics\n",
    "using ForwardDiff, DiffResults\n",
    "\n",
    "using Zygote, ChainRulesCore\n",
    "using ImplicitDifferentiation\n",
    "\n",
    "using CSV, DataFrames\n",
    "using MLUtils\n",
    "using RDKitMinimalLib\n",
    "using JLD2\n",
    "\n",
    "# Multithreaded loss\n",
    "using Zygote: bufferfrom\n",
    "using Base.Threads: @spawn\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.0, 2.260005096581295e-5, 2.1863843008154135e-5, 1.46022174535494e-6, 1.6493904176981177e-7, -6.011351535625539e-8],)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [16.04, 1.0, 3.737, 6.0, 12.504, 152.58]\n",
    "V = volume_NN(X, 1e7, 100.0)\n",
    "∂V∂X = Zygote.gradient(X -> volume_NN(X, 1e7, 100.0), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.0, -4.32664026029552e6, -838766.9527486291, 1.2246980149044194e6, 256678.70349442933, -39357.47330351631],)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#* I want to define a rrule for the backwards pass of Vₗ & pressure simultaneously\n",
    "#* It's wasteful to run the volume solver so many times unnecessarily\n",
    "X = [16.04, 1.0, 3.737, 6.0, 12.504, 152.58]\n",
    "T = 150.0\n",
    "p = saturation_pressure_NN(X, T)\n",
    "# ∂p∂X,  = \n",
    "Zygote.gradient(X -> saturation_pressure_NN(X, T), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 transpose(::Vector{Float64}) with eltype Float64:\n",
       " -0.0  -0.0  -0.0  -0.0  -0.0  -5.78614e-8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [16.04, 1.0, 3.737, 6.0, 12.504, 152.58]\n",
    "f_V(X) = volume_NN(X, 1e7, 100.0)[1]\n",
    "dX = [0.0, 0.0, 0.0, 0.0, 0.0, 1e-6]\n",
    "f_∂V∂X(X) = (f_V(X .+ dX) - f_V(X .- dX))/(2dX)\n",
    "f_∂V∂X(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate training set for liquid density and saturation pressure\n",
    "function create_data(; batch_size=16, n_points=25)\n",
    "    # Create training & validation data\n",
    "    df = CSV.read(\"./pcpsaft_params/SI_pcp-saft_parameters.csv\", DataFrame, header=1)\n",
    "    filter!(row -> occursin(\"Alkane\", row.family), df)\n",
    "    df = first(df, 1) #* Take only first molecule in dataframe\n",
    "    @show df.common_name\n",
    "    mol_data = zip(df.common_name, df.isomeric_smiles, df.molarweight)\n",
    "    println(\"Generating data for $(length(mol_data)) molecules...\")\n",
    "\n",
    "    function make_fingerprint(s::String)::Vector{Float64}\n",
    "        mol = get_mol(s)\n",
    "        @assert !isnothing(mol)\n",
    "\n",
    "        fp = []\n",
    "        # for (nbits, rad) in [(256, 256), (1, 3)]\n",
    "        #* Approximately ECFP4 fingerprint\n",
    "        nbits = 256\n",
    "        rad = 4\n",
    "\n",
    "        fp_details = Dict{String,Any}(\"nBits\" => nbits, \"radius\" => rad)\n",
    "        fp_str = get_morgan_fp(mol, fp_details)\n",
    "        append!(fp, [parse(Float64, string(c)) for c in fp_str])\n",
    "        # end\n",
    "\n",
    "        desc = get_descriptors(mol)\n",
    "        relevant_keys = [\n",
    "            \"CrippenClogP\",\n",
    "            \"NumHeavyAtoms\",\n",
    "            \"amw\",\n",
    "            \"FractionCSP3\",\n",
    "        ]\n",
    "        relevant_desc = [desc[k] for k in relevant_keys]\n",
    "        append!(fp, last.(relevant_desc))\n",
    "\n",
    "        return fp\n",
    "    end\n",
    "\n",
    "    T = Float64\n",
    "    # X_data = Vector{Tuple{Vector{T},T,T,T}}([])\n",
    "    X_data = Vector{Tuple{Vector{T},T,T}}([])\n",
    "    Y_data = Vector{Vector{T}}()\n",
    "\n",
    "    # n = 0\n",
    "    for (name, smiles, Mw) in mol_data\n",
    "        # if n < 20\n",
    "        try\n",
    "            saft_model = PPCSAFT([name])\n",
    "            # saft_model = SAFTVRMie([name])\n",
    "            Tc, pc, Vc = crit_pure(saft_model)\n",
    "\n",
    "            # fp = make_fingerprint(smiles)\n",
    "            fp = [1.0]\n",
    "            # append!(fp, Mw)\n",
    "\n",
    "            T_range = range(0.5 * Tc, 0.975 * Tc, n_points)\n",
    "            for T in T_range\n",
    "                (p_sat, Vₗ_sat, Vᵥ_sat) = saturation_pressure(saft_model, T)\n",
    "\n",
    "                # p = p_sat * 5.0\n",
    "\n",
    "                # Vₗ = volume(saft_model, p, T; phase=:liquid)\n",
    "                push!(X_data, (fp, T, Mw))\n",
    "                push!(Y_data, [Vₗ_sat, p_sat])\n",
    "            end\n",
    "            # n += 1\n",
    "        catch e\n",
    "            println(\"Fingerprint generation failed for $name, $e\")\n",
    "        end\n",
    "        # else\n",
    "        # break\n",
    "        # end\n",
    "    end\n",
    "\n",
    "    #* Remove columns from fingerprints\n",
    "    # Identify zero & one columns\n",
    "    # num_cols = length(X_data[1][1])\n",
    "    # zero_cols = trues(num_cols)\n",
    "    # for (vec, _, _) in X_data\n",
    "    #     zero_cols .&= (vec .== 0)\n",
    "    # end\n",
    "    # keep_cols = .!zero_cols # Create a Mask\n",
    "    # X_data = [(vec[keep_cols], vals...) for (vec, vals...) in X_data] # Apply Mask\n",
    "\n",
    "    # num_cols = length(X_data[1][1])\n",
    "    # one_cols = trues(num_cols)\n",
    "    # for (vec, _, _) in X_data\n",
    "    #     one_cols .&= (vec .== 1)\n",
    "    # end\n",
    "    # keep_cols = .!one_cols # Create a Mask\n",
    "    # X_data = [(vec[keep_cols], vals...) for (vec, vals...) in X_data] # Apply Mask\n",
    "\n",
    "    train_data, test_data = splitobs((X_data, Y_data), at=1.0, shuffle=false)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batchsize=batch_size, shuffle=false)\n",
    "    test_loader = DataLoader(test_data, batchsize=batch_size, shuffle=false)\n",
    "    println(\"n_batches = $(length(train_loader)), batch_size = $batch_size\")\n",
    "    flush(stdout)\n",
    "    return train_loader, test_loader\n",
    "end\n",
    "\n",
    "\n",
    "function create_ff_model(nfeatures)\n",
    "    # Base NN architecture from \"Fitting Error vs Parameter Performance\"\n",
    "    nout = 4\n",
    "    model = Chain(\n",
    "        Dense(nfeatures, nout, x -> x; bias=false, init=zeros32),\n",
    "    )\n",
    "    #* glorot_uniform default initialisation\n",
    "    # model = Chain(\n",
    "    #     Dense(nfeatures, nout * 8, tanh, init=zeros32),\n",
    "    #     Dense(nout * 8, nout * 4, tanh, init=zeros32),\n",
    "    #     Dense(nout * 4, nout * 2, tanh, init=zeros32),\n",
    "    #     Dense(nout * 2, nout, x -> x, init=zeros32), # Allow unbounded negative outputs; parameter values physically bounded in SAFT layer\n",
    "    # )\n",
    "    # model(x) = m, σ, λ_a, λ_r, ϵ\n",
    "\n",
    "    # return nn_model, unbounded_model\n",
    "    return model\n",
    "end\n",
    "\n",
    "function get_idx_from_iterator(iterator, idx)\n",
    "    data_iterator = iterate(iterator)\n",
    "    for _ in 1:idx-1\n",
    "        data_iterator = iterate(iterator, data_iterator[2])\n",
    "    end\n",
    "    return data_iterator[1]\n",
    "end\n",
    "\n",
    "\n",
    "# function SAFT_head(model, X; b=[3.0, 3.5, 7.0, 12.5, 250.0], c=10.0)\n",
    "# function SAFT_head(model, X; b=[2.0, 4.0], c=[1.0, 1.0])\n",
    "function SAFT_head(model, X; b=[2.5, 3.5, 12.0, 250.0], c=Float64[1, 1, 10, 100])\n",
    "    fp, T, Mw = X\n",
    "\n",
    "    # m = 1.8514\n",
    "    # σ = 4.0887\n",
    "    λ_a = 6.0\n",
    "    # λ_r = 13.65\n",
    "    # ϵ = 273.64\n",
    "    # fp, p, T, Mw = X\n",
    "    pred_params = model(fp)\n",
    "\n",
    "    # Add bias and scale\n",
    "    biased_params = @. pred_params * c + b\n",
    "\n",
    "    # Can also fix lambda_a\n",
    "    #! How to do this in AD compatible way, can't do in-place modification\n",
    "    # if biased_params[1] < 1.0\n",
    "    #     biased_params[1] = ones(length(biased_params[1]))\n",
    "    # end\n",
    "\n",
    "    saft_input = vcat(Mw, biased_params[1:2], [λ_a], biased_params[3:4])\n",
    "\n",
    "    # saft_input = vcat(Mw, biased_params[1:2], [λ_a, λ_r], ϵ)\n",
    "    # Vₗ = volume_NN(saft_input, p, T)\n",
    "\n",
    "    # ŷ_1 = !isnan(Vₗ) ? Vₗ : 1e3\n",
    "\n",
    "    Tc = ignore_derivatives() do\n",
    "        critical_temperature_NN(saft_input)\n",
    "    end\n",
    "    # todo include saturation volumes in loss\n",
    "    if T < Tc\n",
    "        p_sat = saturation_pressure_NN(saft_input, T)\n",
    "        # @show saturation_NN(saft_input, T)\n",
    "        # p_sat, Vₗ_sat, Vᵥ_sat = saturation_NN(saft_input, T)\n",
    "        if !isnan(p_sat)\n",
    "            Vₗ_sat = volume_NN(saft_input, p_sat, T)\n",
    "            # ŷ_2 = sat_p\n",
    "            ŷ = [Vₗ_sat, p_sat]\n",
    "        else\n",
    "            # println(\"sat_p is NaN at T = $T, saft_input = $saft_input\")\n",
    "            ŷ = [nothing, nothing]\n",
    "        end\n",
    "    else\n",
    "        ŷ = [nothing, nothing]\n",
    "    end\n",
    "\n",
    "    return ŷ\n",
    "end\n",
    "\n",
    "function eval_loss(X_batch, y_batch, metric, model)\n",
    "    batch_loss = 0.0\n",
    "    n = 0\n",
    "    for (X, y_vec) in zip(X_batch, y_batch)\n",
    "        # y = y_vec[1]\n",
    "        ŷ_vec = SAFT_head(model, X)\n",
    "\n",
    "        for (ŷ, y) in zip(ŷ_vec, y_vec)\n",
    "            if !isnothing(ŷ)\n",
    "                batch_loss += metric(y, ŷ)\n",
    "                n += 1\n",
    "            end\n",
    "        end\n",
    "\n",
    "    end\n",
    "    if n > 0\n",
    "        batch_loss /= n\n",
    "    end\n",
    "    # penalize batch_loss depending on how many failed\n",
    "    # batch_loss += length(y_batch) - n\n",
    "\n",
    "    return batch_loss\n",
    "end\n",
    "\n",
    "function eval_loss_par(X_batch, y_batch, metric, model, n_chunks)\n",
    "    n = length(X_batch)\n",
    "    chunk_size = n ÷ n_chunks\n",
    "\n",
    "    p = bufferfrom(zeros(n_chunks))\n",
    "\n",
    "    # Creating views for each chunk\n",
    "    X_chunks = vcat([view(X_batch, (i-1)*chunk_size+1:i*chunk_size) for i in 1:n_chunks-1], [view(X_batch, (n_chunks-1)*chunk_size+1:n)])\n",
    "    y_chunks = vcat([view(y_batch, (i-1)*chunk_size+1:i*chunk_size) for i in 1:n_chunks-1], [view(y_batch, (n_chunks-1)*chunk_size+1:n)])\n",
    "\n",
    "    @sync begin\n",
    "        for i = 1:n_chunks\n",
    "            @spawn begin\n",
    "                p[i] = eval_loss(X_chunks[i], y_chunks[i], metric, model)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return sum(p) / n_chunks # average partial losses\n",
    "end\n",
    "\n",
    "function percent_error(y, ŷ)\n",
    "    return 100 * abs(y - ŷ) / y\n",
    "end\n",
    "\n",
    "function mse(y, ŷ)\n",
    "    return ((y - ŷ) / y)^2\n",
    "end\n",
    "\n",
    "function finite_diff_grads(model, x, y; ϵ=1e-8)\n",
    "    grads = []\n",
    "    for p in Flux.params(model)\n",
    "        push!(grads, zeros(size(p)))\n",
    "    end\n",
    "\n",
    "    for (i, p) in enumerate(Flux.params(model))\n",
    "        for j in eachindex(p)\n",
    "            tmp = p[j]\n",
    "            p[j] = tmp + ϵ\n",
    "            J1 = eval_loss(x, y, mse, model)\n",
    "            p[j] = tmp - ϵ\n",
    "            J2 = eval_loss(x, y, mse, model)\n",
    "            p[j] = tmp\n",
    "            grads[i][j] = (J1 - J2) / (2 * ϵ)\n",
    "        end\n",
    "    end\n",
    "    return grads\n",
    "end\n",
    "\n",
    "function train_model!(model, train_loader, test_loader; epochs=10)\n",
    "    optim = Flux.setup(Flux.Adam(0.01), model) # 1e-3 usually safe starting LR\n",
    "    # optim = Flux.setup(Descent(0.001), model)\n",
    "\n",
    "    println(\"training on $(Threads.nthreads()) threads\")\n",
    "    flush(stdout)\n",
    "\n",
    "    for epoch in 1:epochs\n",
    "        batch_loss = 0.0\n",
    "        for (X_batch, y_batch) in train_loader\n",
    "\n",
    "            loss, grads = Flux.withgradient(model) do m\n",
    "                # loss = eval_loss_par(X_batch, y_batch, percent_error, m, Threads.nthreads())\n",
    "                loss = eval_loss(X_batch, y_batch, mse, m)\n",
    "                loss\n",
    "            end\n",
    "            batch_loss += loss\n",
    "            @assert !isnan(loss)\n",
    "\n",
    "            # grads_fd = finite_diff_grads(model, X_batch, y_batch)\n",
    "            # @show grads[1]\n",
    "            # @show grads_fd      # Show FD gradients\n",
    "\n",
    "            Flux.update!(optim, model, grads[1])\n",
    "        end\n",
    "        batch_loss /= length(train_loader)\n",
    "        epoch % 1 == 0 && println(\"epoch $epoch: batch_loss = $batch_loss\")\n",
    "        flush(stdout)\n",
    "    end\n",
    "end\n",
    "\n",
    "function main(; epochs=15)\n",
    "    train_loader, test_loader = create_data(n_points=20, batch_size=20) # Should make 5 batches / epoch. 256 / 8 gives 32 evaluations per thread\n",
    "    @show n_features = length(first(train_loader)[1][1][1])\n",
    "\n",
    "    model = create_ff_model(n_features)\n",
    "    # @show model.layers[1].weight, model([1.0])\n",
    "    train_model!(model, train_loader, test_loader; epochs=epochs)\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.common_name = [\"n-butane\"]\n",
      "Generating data for 1 molecules...\n",
      "n_batches = 1, batch_size = 20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features = length((((first(train_loader))[1])[1])[1]) = 1\n",
      "training on 1 threads"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: batch_loss = 0.24360634636006565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: batch_loss = 0.21856524198932484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: batch_loss = 0.19263854094403393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: batch_loss = 0.16619345097130594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: batch_loss = 0.13975286024385647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: batch_loss = 0.11404064450074192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: batch_loss = 0.09003176568119306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: batch_loss = 0.06899334499720985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: batch_loss = 0.05247330314489913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: batch_loss = 0.042122478994858555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: batch_loss = 0.0391454677641264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12: batch_loss = 0.043319216356720966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13: batch_loss = 0.05202216759451302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14: batch_loss = 0.06022449516294287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15: batch_loss = 0.06327247884927467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16: batch_loss = 0.060784066247526546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17: batch_loss = 0.055225912400765645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18: batch_loss = 0.04895451794010682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19: batch_loss = 0.043618980411431404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20: batch_loss = 0.04010837696824411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21: batch_loss = 0.03856948063716571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22: batch_loss = 0.038633299998410905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23: batch_loss = 0.03969377243365802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24: batch_loss = 0.04112327294322722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25: batch_loss = 0.04239919555803306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26: batch_loss = 0.04315670889680262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27: batch_loss = 0.04319422484917013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28: batch_loss = 0.042454953748414515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29: batch_loss = 0.04099959072430672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30: batch_loss = 0.038977455239669535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31: batch_loss = 0.03659793492772055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32: batch_loss = 0.03410143623679026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33: batch_loss = 0.03172833268222639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34: batch_loss = 0.02968562352066449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35: batch_loss = 0.02811362015532907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36: batch_loss = 0.027058483149606793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37: batch_loss = 0.02645943041875386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38: batch_loss = 0.0261596395675034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39: batch_loss = 0.025945237169700215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40: batch_loss = 0.025606605471235964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41: batch_loss = 0.025003358830701417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42: batch_loss = 0.024106244268971917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43: batch_loss = 0.022995793192818165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44: batch_loss = 0.021819498230467894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45: batch_loss = 0.020731274271898685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46: batch_loss = 0.01984154977902969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47: batch_loss = 0.019193999730944638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48: batch_loss = 0.01876899217295455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49: batch_loss = 0.018504268912652562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50: batch_loss = 0.018321426634539912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51: batch_loss = 0.018149429519253635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52: batch_loss = 0.01794038242589676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53: batch_loss = 0.017676194738658398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54: batch_loss = 0.017366967765553104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55: batch_loss = 0.017043072526420868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56: batch_loss = 0.016743419032307787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57: batch_loss = 0.016502717597357698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58: batch_loss = 0.016340681520199702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59: batch_loss = 0.016255948265741706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60: batch_loss = 0.016226615573163874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61: batch_loss = 0.016217505650797152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62: batch_loss = 0.01619187215250882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63: batch_loss = 0.016123276806015822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64: batch_loss = 0.016003045856894885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65: batch_loss = 0.015840657593047626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66: batch_loss = 0.015657648162162398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67: batch_loss = 0.015478366263005899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68: batch_loss = 0.015321619514544383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69: batch_loss = 0.015196069566646746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70: batch_loss = 0.015100090878134933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71: batch_loss = 0.015025033222085126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72: batch_loss = 0.014959933099479655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73: batch_loss = 0.014895779010354309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74: batch_loss = 0.014828072457162656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75: batch_loss = 0.014757210106147601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76: batch_loss = 0.01468700101934973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77: batch_loss = 0.01462210501296175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78: batch_loss = 0.014565424182038805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79: batch_loss = 0.014516384314042813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80: batch_loss = 0.014470682040736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81: batch_loss = 0.0144215217061829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82: batch_loss = 0.014361806541016205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83: batch_loss = 0.014286400802941857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84: batch_loss = 0.01419358939329855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85: batch_loss = 0.014085258122301025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86: batch_loss = 0.01396587049628567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87: batch_loss = 0.013840790724252297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88: batch_loss = 0.013714664201992846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89: batch_loss = 0.013590417224626302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90: batch_loss = 0.01346907934736311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91: batch_loss = 0.013350279601798349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92: batch_loss = 0.013233048855726598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93: batch_loss = 0.013116537281279001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94: batch_loss = 0.013000380395721833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95: batch_loss = 0.012884641750578952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96: batch_loss = 0.012769449281515733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97: batch_loss = 0.01265455819183437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98: batch_loss = 0.012539071724648099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99: batch_loss = 0.012421466753638448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100: batch_loss = 0.012299923169666882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(1 => 4, #488; bias=false),      \u001b[90m# 4 parameters\u001b[39m\n",
       ") "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = main(;epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: code to create saturation envelopes for given envelopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float32}:\n",
       " -0.093466766\n",
       " -0.089043505\n",
       "  0.089826174\n",
       " -0.093140006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fieldnames(typeof(m.layers[1]))\n",
    "m.layers[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "   2.406533233821392\n",
       "   3.410956494510174\n",
       "  12.898261740803719\n",
       " 240.68599939346313"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = [2.5, 3.5, 12, 250.0]\n",
    "# b = [2.0, 4.0, 250.0]\n",
    "c = Float64[1, 1, 10, 100]\n",
    "# b = [2.0, 4.0]\n",
    "# c = Float64[1, 1]\n",
    "params = m([1.0]) .* c .+ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: plot not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: plot not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/SAFT_ML/14_liquid_density_training.ipynb:4"
     ]
    }
   ],
   "source": [
    "Mw = 58.12\n",
    "λ_a = 6.0\n",
    "\n",
    "plot(;box=:on, dpi=400, xlabel=\"log10(V / m³)\", ylabel=\"T / K\")\n",
    "function f(model, c, label)\n",
    "    # Create saturation envelope\n",
    "    Tc, pc, Vc = crit_pure(model)\n",
    "    T_range = range(0.5 * Tc, 0.9999 * Tc, 500)\n",
    "\n",
    "    p_sat =  Float64[]\n",
    "    Vl_sat = Float64[]\n",
    "    Vv_sat = Float64[]\n",
    "    for T in T_range\n",
    "        (p, Vl, Vv) = saturation_pressure(model, T)\n",
    "        push!(p_sat, p)\n",
    "        push!(Vl_sat, Vl)\n",
    "        push!(Vv_sat, Vv)\n",
    "    end\n",
    "\n",
    "    # plot!(T_range, p_sat, label=\"saturation pressure\")\n",
    "    plot!(log10.(Vl_sat), T_range, label=label, lw=2, color=c)\n",
    "    plot!(log10.(Vv_sat), T_range, label=\"\", lw=2, color=c)\n",
    "    scatter!([log10(Vc)], [Tc], label=\"\", color=c)\n",
    "end\n",
    "\n",
    "pred_model = make_model(vcat(Mw, params[1:2], [λ_a], params[3:4])...)\n",
    "base_model = SAFTVRMie([\"n-butane\"])\n",
    "f(pred_model, 1, \"4 params regressed\")\n",
    "f(base_model, 2, \"Base SAFT-VR-Mie\")\n",
    "#* Plot nominal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8514, 4.0887, 273.64, 13.65)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = CSV.read(\"./pcpsaft_params/SI_pcp-saft_parameters.csv\", DataFrame, header=1)\n",
    "filter!(row -> occursin(\"Alkane\", row.family), df)\n",
    "df = first(df, 1) #* Take only first molecule in dataframe\n",
    "mol_data = zip(df.common_name, df.isomeric_smiles, df.molarweight)\n",
    "saft_model = SAFTVRMie([first(mol_data)[1]])\n",
    "saft_model.params.segment.values[1], saft_model.params.sigma.values[1]*1e10, saft_model.params.epsilon.values[1], saft_model.params.lambda_r.values[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
