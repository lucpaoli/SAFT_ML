{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a chain rule to calculate the loss function @ saturation w/out propagating derivatives through saturation solver\n",
    "# This was done in the Language of Molecules paper.\n",
    "\n",
    "# 1_differentiable_saft works when no solvers are involved, i.e. for properties specified with a given (V, T)\n",
    "# if, instead, we want to solve for saturation conditions, then I have the old problem of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/SAFT_ML`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant UNIT_FORMATS. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.activate(\".\")\n",
    "\n",
    "using Revise\n",
    "using Clapeyron\n",
    "includet(\"./saftvrmienn.jl\")\n",
    "# These are functions we're going to overload for SAFTVRMieNN\n",
    "import Clapeyron: a_res, saturation_pressure, pressure\n",
    "\n",
    "using Flux\n",
    "using Plots\n",
    "using ForwardDiff, DiffResults\n",
    "\n",
    "using Zygote, ChainRulesCore\n",
    "using ImplicitDifferentiation\n",
    "\n",
    "using CSV, DataFrames\n",
    "using MLUtils\n",
    "using RDKitMinimalLib \n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 16.267432682904257\n",
      "(∂p∂X, ∂p∂T) = "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(([-0.0, -109.93750954832143, -6.105482508288177, 21.53097976724112, 4.416594844872478, -1.3639866231328097],), (3.5520440640281374,))\n"
     ]
    }
   ],
   "source": [
    "X = [16.04, 1.0, 3.737, 6.0, 12.504, 152.58]\n",
    "T = 100.0\n",
    "\n",
    "X = [114.14099884033203, 1.6983753442764282, 7.993192672729492, 8.710663437843323, 18.967856884002686, 248.48995435237885]\n",
    "# T = 345.38165\n",
    "\n",
    "p = saturation_pressure_NN(X, T)\n",
    "∂p∂X = Zygote.gradient(X -> saturation_pressure_NN(X, T), X)\n",
    "∂p∂T = Zygote.gradient(T -> saturation_pressure_NN(X, T), T)\n",
    "@show p\n",
    "@show ∂p∂X, ∂p∂T;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: generating data for 80 molecules\n",
      "└ @ Main /home/luc/SAFT_ML/6_sat_solver_NN.ipynb:12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15-element DataLoader(::Tuple{SubArray{Tuple{Vector{Float32}, Float32, Float32}, 1, Vector{Tuple{Vector{Float32}, Float32, Float32}}, Tuple{Vector{Int64}}, false}, SubArray{Vector{Float32}, 1, Vector{Vector{Float32}}, Tuple{Vector{Int64}}, false}}, batchsize=32)\n",
       "  with first element:\n",
       "  (32-element Vector{Tuple{Vector{Float32}, Float32, Float32}}, 32-element Vector{Vector{Float32}},)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up data creation & loading here \n",
    "# Currently random\n",
    "# nsamples = 10\n",
    "# nfeatures = 4\n",
    "# nout = 5\n",
    "# X = rand(Float32, nfeatures, nsamples)\n",
    "# y = rand(Float32, nout, nsamples)\n",
    "\n",
    "df = CSV.read(\"./pcpsaft_params/SI_pcp-saft_parameters.csv\", DataFrame, header=1)\n",
    "filter!(row -> occursin(\"Alkane\", row.family), df)\n",
    "mol_data = zip(df.common_name, df.isomeric_smiles, df.molarweight)\n",
    "@info \"generating data for $(length(mol_data)) molecules\"\n",
    "\n",
    "function make_fingerprint(s::String)::Vector{Float32}\n",
    "    mol = get_mol(s)\n",
    "    @assert !isnothing(mol)\n",
    "\n",
    "    fp = []\n",
    "    fp_details = Dict{String,Any}(\"nBits\" => 512, \"radius\" => 4)\n",
    "    fp_str = get_morgan_fp(mol, fp_details)\n",
    "    append!(fp, [parse(Float32, string(c)) for c in fp_str])\n",
    "\n",
    "    desc = get_descriptors(mol)\n",
    "    relevant_keys = [\n",
    "        \"CrippenClogP\",\n",
    "        \"NumHeavyAtoms\",\n",
    "        \"amw\",\n",
    "        \"FractionCSP3\",\n",
    "    ]\n",
    "    relevant_desc = [desc[k] for k in relevant_keys]\n",
    "    append!(fp, last.(relevant_desc))\n",
    "\n",
    "    return fp\n",
    "end\n",
    "\n",
    "T = Float32\n",
    "X_data = Vector{Tuple{Vector{T},T,T}}([])\n",
    "Y_data = Vector{Vector{T}}()\n",
    "\n",
    "n = 30\n",
    "for (name, smiles, Mw) in mol_data\n",
    "    saft_model = PPCSAFT([name])\n",
    "    Tc, pc, Vc = crit_pure(saft_model)\n",
    "\n",
    "    fp = make_fingerprint(smiles)\n",
    "\n",
    "    T_range = range(0.5 * Tc, 0.975 * Tc, n)\n",
    "    for T in T_range\n",
    "        (p₀, V_vec...) = saturation_pressure(saft_model, T)\n",
    "        push!(X_data, (fp, T, Mw))\n",
    "        push!(Y_data, Float32[p₀])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Shuffle all samples into a random order\n",
    "# Package into data loaders\n",
    "# batchsize = 10\n",
    "# train_data = DataLoader((X_data, y_data), batchsize=batchsize, shuffle=true)\n",
    "#* shuffle=true randomises observation order every iteration\n",
    "\n",
    "#* Remove zero columns from fingerprints\n",
    "# Identify Zero Columns\n",
    "num_cols = length(X_data[1][1])\n",
    "zero_cols = trues(num_cols)\n",
    "for (vec, _, _) in X_data\n",
    "    zero_cols .&= (vec .== 0)\n",
    "end\n",
    "\n",
    "# Create a Mask\n",
    "keep_cols = .!zero_cols\n",
    "\n",
    "# Apply Mask\n",
    "X_data = [(vec[keep_cols], val1, val2) for (vec, val1, val2) in X_data]\n",
    "\n",
    "train_data, test_data = splitobs((X_data, Y_data), at=0.8, shuffle = true)\n",
    "\n",
    "train_loader = DataLoader(train_data, batchsize=32, shuffle=true)\n",
    "test_loader = DataLoader(test_data, batchsize=32, shuffle=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Beginning training...\n",
      "└ @ Main /home/luc/SAFT_ML/6_sat_solver_NN.ipynb:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: (μ=2230.331, σ=14829.467), Percent Error: 1082.3358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: (μ=0.98204464, σ=0.009505792), Percent Error: 590.7165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: (μ=0.98219174, σ=0.010176442), Percent Error: 426.8456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: (μ=0.9820813, σ=0.009836892), Percent Error: 344.90903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: (μ=0.9816503, σ=0.008563999), Percent Error: 295.74265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: (μ=0.9807997, σ=0.011182162), Percent Error: 197.39743\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "syntax: unexpected \"end\"",
     "output_type": "error",
     "traceback": [
      "syntax: unexpected \"end\"\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/SAFT_ML/6_sat_solver_NN.ipynb:88"
     ]
    }
   ],
   "source": [
    "# Base NN architecture from \"Fitting Error vs Parameter Performance\"\n",
    "nfeatures = length(X_data[1][1])\n",
    "nout = 5\n",
    "unbounded_model = Chain(\n",
    "    Dense(nfeatures, 2048, selu),\n",
    "    Dense(2048, 1024, selu),\n",
    "    Dense(1024, 512, selu),\n",
    "    Dense(512, 128, selu),\n",
    "    Dense(128, 32, selu),\n",
    "    Dense(32, nout, selu),\n",
    ")\n",
    "# model(x) = m, σ, λ_a, λ_r, ϵ\n",
    "\n",
    "opt = ADAM(1e-3)\n",
    "\n",
    "# Add constant bias to the model output\n",
    "b = [\n",
    "    3.0,\n",
    "    3.5,\n",
    "    7.0,\n",
    "    12.5,\n",
    "    250.0,\n",
    "]\n",
    "nn_model(x) = unbounded_model(x)/100.0 .+ b\n",
    "\n",
    "# Training loop\n",
    "@info \"Beginning training...\"\n",
    "epochs = 10\n",
    "epoch_percent_loss_vec = Float32[]\n",
    "loss_vec = Float32[]\n",
    "mean_loss_vec = Float32[]\n",
    "\n",
    "loss_fn(X_batch, y_batch) = begin\n",
    "    n = 0\n",
    "    batch_loss = 0.0\n",
    "    for (X, y) in zip(X_batch, y_batch)\n",
    "        fp, T, Mw = X\n",
    "        y = y[1]\n",
    "\n",
    "        X_pred = nn_model(fp)\n",
    "        X_saft = vcat(Mw, X_pred)\n",
    "        Tc = critical_temperature_NN(X_saft)\n",
    "        if T < Tc\n",
    "            ŷ = saturation_pressure_NN(X_saft, T)\n",
    "            if !isnan(ŷ)\n",
    "                n += 1\n",
    "                batch_loss += ((ŷ - y) / y)^2\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    if n != 0\n",
    "        batch_loss /= n\n",
    "    end\n",
    "    batch_loss\n",
    "end\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    epoch_loss_vec = Float32[]\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for (X_batch, y_batch) in train_loader\n",
    "        # @show loss_fn(X_batch, y_batch) \n",
    "\n",
    "        batch_loss = 0.0\n",
    "        grads = Zygote.gradient(Flux.params(unbounded_model)) do\n",
    "            batch_loss = loss_fn(X_batch, y_batch)\n",
    "        end\n",
    "\n",
    "        # Update model parameters\n",
    "        Flux.update!(opt, Flux.params(unbounded_model), grads)\n",
    "\n",
    "        append!(epoch_loss_vec, batch_loss)\n",
    "        append!(epoch_percent_loss_vec, 100 * sqrt(batch_loss))\n",
    "    end\n",
    "    mean_loss = mean(epoch_loss_vec)\n",
    "    mean_percent_loss = mean(epoch_percent_loss_vec)\n",
    "    append!(loss_vec, epoch_loss_vec)\n",
    "    append!(mean_loss_vec, mean_loss)\n",
    "\n",
    "    if epoch in [1, 2, 3, 4, 5, 10] || epoch % 5 == 0 || epoch == epochs\n",
    "        println(\"Epoch: $epoch, Loss: (μ=$mean_loss, σ=$(std(epoch_loss_vec))), Percent Error: $mean_percent_loss\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: (μ=0.98062664, σ=0.009668167), Percent Error: 188.4545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: (μ=0.9798928, σ=0.01088991), Percent Error: 160.5026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: (μ=0.9787283, σ=0.010470124), Percent Error: 145.84695\n"
     ]
    }
   ],
   "source": [
    "epochs2 = 50\n",
    "for epoch in epochs:epochs2\n",
    "    epoch_loss_vec = Float32[]\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for (X_batch, y_batch) in train_loader\n",
    "        # @show loss_fn(X_batch, y_batch) \n",
    "\n",
    "        batch_loss = 0.0\n",
    "        grads = Zygote.gradient(Flux.params(unbounded_model)) do\n",
    "            batch_loss = loss_fn(X_batch, y_batch)\n",
    "        end\n",
    "\n",
    "        # Update model parameters\n",
    "        Flux.update!(opt, Flux.params(unbounded_model), grads)\n",
    "\n",
    "        append!(epoch_loss_vec, batch_loss)\n",
    "        append!(epoch_percent_loss_vec, 100 * sqrt(batch_loss))\n",
    "    end\n",
    "    mean_loss = mean(epoch_loss_vec)\n",
    "    mean_percent_loss = mean(epoch_percent_loss_vec)\n",
    "    append!(loss_vec, epoch_loss_vec)\n",
    "    append!(mean_loss_vec, mean_loss)\n",
    "\n",
    "    if epoch in [1, 2, 3, 4, 5, 10] || epoch % 5 == 0 || epoch == epochs\n",
    "        println(\"Epoch: $epoch, Loss: (μ=$mean_loss, σ=$(std(epoch_loss_vec))), Percent Error: $mean_percent_loss\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! The model doesn't start with any thermodynamic knowledge. Is there any database we could pre-train on?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
