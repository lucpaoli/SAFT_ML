{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/SAFT_ML`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant UNIT_FORMATS. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "using Clapeyron\n",
    "import Clapeyron: a_res\n",
    "\n",
    "using MolecularGraph, Graphs\n",
    "using Plots\n",
    "\n",
    "using Flux\n",
    "using Flux: onecold, onehotbatch, logitcrossentropy\n",
    "using Flux: DataLoader\n",
    "using GraphNeuralNetworks\n",
    "using MLDatasets\n",
    "using MLUtils\n",
    "using OneHotArrays\n",
    "using LinearAlgebra, Random, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atom_symbol(mol): atom letters as a symbol e.g. :C, :O and :N\n",
    "# charge(mol): electric charge of the atom. only integer charge is allowed in the model\n",
    "# multiplicity(mol): 1: no unpaired electron(default), 2: radical, 3: biradical\n",
    "# lone_pair(mol): number of lone pair on the atom\n",
    "# implicit_hydrogens(mol): number of implicit hydrogens that are not appear as graph vertices but automatically calculated, drawn in image and used for calculation of other descriptors.\n",
    "# valence(mol): number of atom valence, specific to each atom species and considering electric charge. Implicit number of hydrogens is obtained by subtracting the degree of the vertex from the valence.\n",
    "# is_aromatic(mol): whether the atom is aromatic or not. only binary aromaticity is allowed in the model.\n",
    "# pi_electron(mol): number of pi electrons\n",
    "# hybridization(mol): orbital hybridization e.g. sp, sp2 and sp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNGraph:\n",
       "  num_nodes: 7\n",
       "  num_edges: 12\n",
       "  ndata:\n",
       "\tx = 11×7 Matrix{Float32}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function make_graph_from_smiles(smiles::String)\n",
    "    molgraph = smilestomol(smiles)\n",
    "\n",
    "    g = Graph(nv(molgraph))\n",
    "    for e in edges(molgraph)\n",
    "        add_edge!(g, e.src, e.dst)\n",
    "    end\n",
    "\n",
    "    # Should number of hydrogens be one-hot encoded?\n",
    "    f(vec, enc) = hcat(map(x -> onehot(x, enc), vec)...)\n",
    "    num_h = f(implicit_hydrogens(molgraph), [0, 1, 2, 3, 4])\n",
    "    hybrid = f(hybridization(molgraph), [:sp, :sp2, :sp3])\n",
    "    atoms = f(atom_symbol(molgraph), [:C, :O, :N])\n",
    "\n",
    "    # Node data should be matrix (num_features, num_nodes)\n",
    "    # Matrix has num_nodes columns, num_features rows\n",
    "    ndata = Float32.(vcat(num_h, hybrid, atoms))\n",
    "\n",
    "    g = GNNGraph(g, ndata = ndata, edata = nothing)\n",
    "    return g\n",
    "end\n",
    "\n",
    "g = make_graph_from_smiles(\"CC=CC(CC=O)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11×7 Matrix{Float32}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       " 0.0  1.0  1.0  0.0  0.0  1.0  0.0\n",
       " 0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       " 1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  1.0  1.0  0.0  0.0  1.0  1.0\n",
       " 1.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.ndata.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over molecules in dataset and build graph for each one\n",
    "# Initially sample data for hydrocarbons\n",
    "#! isobutane, isopentane not defined for SAFTVRMie\n",
    "species = [\n",
    "    \"methane\",\n",
    "    \"ethane\",\n",
    "    \"propane\",\n",
    "    \"butane\",\n",
    "    \"pentane\",\n",
    "    \"hexane\",\n",
    "    \"heptane\",\n",
    "    \"octane\",\n",
    "    \"nonane\",\n",
    "    # \"decane\",\n",
    "]\n",
    "\n",
    "# Define smiles map\n",
    "smiles_map = Dict(\n",
    "    \"methane\" => \"C\",\n",
    "    \"ethane\" => \"CC\",\n",
    "    \"propane\" => \"CCC\",\n",
    "    \"butane\" => \"CCCC\",\n",
    "    \"isobutane\" => \"CC(C)C\",\n",
    "    \"pentane\" => \"CCCCC\",\n",
    "    \"isopentane\" => \"CC(C)CC\",\n",
    "    \"hexane\" => \"CCCCCC\",\n",
    "    \"heptane\" => \"CCCCCCC\",\n",
    "    \"octane\" => \"CCCCCCCC\",\n",
    "    \"nonane\" => \"CCCCCCCCC\",\n",
    "    \"decane\" => \"CCCCCCCCCC\",\n",
    ")\n",
    "\n",
    "# X data contains graph, V, T\n",
    "# Y data contains a_res\n",
    "#* Sampling data along saturation curve\n",
    "T = Float32\n",
    "# X_data = Vector{Tuple{typeof(g),T,T, String}}([])\n",
    "# Y_data = Vector{Vector{T}}()\n",
    "\n",
    "T = GNNGraph{Tuple{Vector{Int64}, Vector{Int64}, Nothing}}\n",
    "graphs = T[]\n",
    "states = Tuple{Float32, Float32, String}[]\n",
    "Y_data = Float32[]\n",
    "\n",
    "n = 30\n",
    "for s in species\n",
    "    # model = GERG2008([s])\n",
    "    model = SAFTVRMie([s])\n",
    "    Tc, pc, Vc = crit_pure(model)\n",
    "    smiles = smiles_map[s]\n",
    "\n",
    "    # fingerprint = make_fingerprint(smiles)\n",
    "    g = make_graph_from_smiles(smiles)\n",
    "\n",
    "    T_range = range(0.5 * Tc, 0.99 * Tc, n)\n",
    "    # V_range = range(0.5 * Vc, 1.5 * Vc, n) # V could be sampled from a logspace\n",
    "    for T in T_range\n",
    "        (p₀, V_vec...) = saturation_pressure(model, T)\n",
    "        for V in V_vec\n",
    "            push!(graphs, g)\n",
    "            push!(states, (V, T, s))\n",
    "            \n",
    "            a = a_res(model, V, T, [1.0])\n",
    "            @assert !isnan(a) \"a is NaN at $(V), $(T), $s\"\n",
    "            push!(Y_data, a)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNGraph:\n",
       "  num_nodes: 9\n",
       "  num_edges: 16\n",
       "  ndata:\n",
       "\tx = 11×9 Matrix{Float32}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.07785356f0, 392.35257f0, \"nonane\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.020128421f0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 500\n",
    "display(graphs[n])\n",
    "display(states[n])\n",
    "display(Y_data[n])\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNGraph:\n",
       "  num_nodes: 163\n",
       "  num_edges: 262\n",
       "  num_graphs: 32\n",
       "  ndata:\n",
       "\tx = 11×163 Matrix{Float32}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data, test_data = splitobs((graphs, states, Y_data), at = 0.8, shuffle = true) |> getobs\n",
    "\n",
    "Random.seed!(0)\n",
    "train_loader = DataLoader(train_data, batchsize = 32, shuffle = true)\n",
    "test_loader = DataLoader(test_data, batchsize = 32, shuffle = false)\n",
    "\n",
    "# Testing if batching works. This will be used when training\n",
    "# This should produce a single GNNGraph object with a matrix of ndata\n",
    "vec_gs, _ = first(train_loader)\n",
    "MLUtils.batch(vec_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function create_model(nin, nh, nout)\n",
    "    GNNChain(\n",
    "        GraphConv(nin => nh, relu),\n",
    "        # GraphConv(nh => nh, relu),\n",
    "        # GraphConv(nh => nh),\n",
    "        GlobalPool(mean), # Average the node features\n",
    "        Dropout(0.2),\n",
    "        Dense(nh, nout),\n",
    "    )\n",
    "end\n",
    "\n",
    "function eval_loss(model, data_loader, device)\n",
    "    loss = 0.0\n",
    "    for (g, states, y) in data_loader\n",
    "        g, y = MLUtils.batch(g) |> device, y |> device\n",
    "        ŷ = model(g, g.ndata.x)'\n",
    "        loss += Flux.mse(ŷ, y)\n",
    "    end\n",
    "    return loss / length(data_loader)\n",
    "end\n",
    "\n",
    "function train!(model; epochs=12, η=1e-3, infotime=3)\n",
    "    # device = Flux.gpu # uncomment this for GPU training\n",
    "    device = Flux.cpu\n",
    "    model = model |> device\n",
    "    opt = Flux.setup(Adam(1e-3), model)\n",
    "\n",
    "    function report(epoch)\n",
    "        train = eval_loss(model, train_loader, device)\n",
    "        test = eval_loss(model, test_loader, device)\n",
    "        @info (; epoch, train, test)\n",
    "    end\n",
    "\n",
    "    report(0)\n",
    "    for epoch in 1:epochs\n",
    "        for (g, states, y) in train_loader\n",
    "            g, y = MLUtils.batch(g) |> device, y |> device\n",
    "            loss = 0.0\n",
    "            grads = Flux.gradient(model) do model\n",
    "                ŷ = model(g, g.ndata.x)'\n",
    "                loss = Flux.mse(ŷ, y)\n",
    "            end\n",
    "            Flux.update!(opt, model, grads[1])\n",
    "        end\n",
    "        epoch % infotime == 0 && report(epoch)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: (epoch = 0, train = 10.289446728570121, test = 8.44406795501709)\n",
      "└ @ Main /home/luc/SAFT_ML/4_gnn_saft.ipynb:31\n",
      "┌ Info: (epoch = 3, train = 8.590846572603498, test = 7.037330150604248)\n",
      "└ @ Main /home/luc/SAFT_ML/4_gnn_saft.ipynb:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: (epoch = 6, train = 7.50623973778316, test = 6.122561097145081)\n",
      "└ @ Main /home/luc/SAFT_ML/4_gnn_saft.ipynb:31\n",
      "┌ Info: (epoch = 9, train = 6.5303173405783514, test = 5.111987233161926)\n",
      "└ @ Main /home/luc/SAFT_ML/4_gnn_saft.ipynb:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: (epoch = 12, train = 5.40480945791517, test = 4.426450252532959)\n",
      "└ @ Main /home/luc/SAFT_ML/4_gnn_saft.ipynb:31\n"
     ]
    }
   ],
   "source": [
    "nin = 11\n",
    "nh = 16\n",
    "nout = 1\n",
    "model = create_model(nin, nh, nout)\n",
    "train!(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
