{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/SAFT_ML`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, DelimitedFiles, Clapeyron, PyCall\n",
    "import PyPlot; const plt = PyPlot ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mthread = 1 warning: only found 5 / 17 columns around data row: 1845. Filling remaining columns with `missing`\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ CSV ~/.julia/packages/CSV/OnldF/src/file.jl:577\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Open and structure Esper et al. Statistics data\n",
    "# Set missing values to -1 for easier processing (all valid values are positive)\n",
    "\n",
    "raw_data_statistics = CSV.read(\"Esper et al Statistics (CSV).csv\",DataFrame,header=1) \n",
    "processed_data_statistics = raw_data_statistics[1:1842,1:15]\n",
    "\n",
    "for i = 1:nrow(processed_data_statistics)\n",
    "    processed_data_statistics[i,:p_sat_AAD_outliers] = replace(processed_data_statistics[i,:p_sat_AAD_outliers], r\"[()]\" => \"\")\n",
    "    processed_data_statistics[i,:rho_vap_AAD_outliers] = replace(processed_data_statistics[i,:rho_vap_AAD_outliers], r\"[()]\" => \"\")\n",
    "    processed_data_statistics[i,:p_sat_n_points_outliers] = replace(processed_data_statistics[i,:p_sat_n_points_outliers], r\"[()]\" => \"\")\n",
    "    processed_data_statistics[i,:rho_vap_n_points_outliers] = replace(processed_data_statistics[i,:rho_vap_n_points_outliers], r\"[()]\" => \"\")\n",
    "\n",
    "    processed_data_statistics[i,:p_sat_AAD_outliers] = replace(processed_data_statistics[i,:p_sat_AAD_outliers], r\"-\" => -1)\n",
    "    processed_data_statistics[i,:rho_liq_sat_AAD] = replace(processed_data_statistics[i,:rho_liq_sat_AAD], r\"-\" => -1)\n",
    "    processed_data_statistics[i,:rho_liq_sp_AAD] = replace(processed_data_statistics[i,:rho_liq_sp_AAD], r\"-\" => -1)\n",
    "    processed_data_statistics[i,:rho_vap_AAD_outliers] = replace(processed_data_statistics[i,:rho_vap_AAD_outliers], r\"-\" => -1)\n",
    "    processed_data_statistics[i,:p_sat_n_points_outliers] = replace(processed_data_statistics[i,:p_sat_n_points_outliers], r\"-\" => -1)\n",
    "    processed_data_statistics[i,:rho_liq_sat_n_points] = replace(processed_data_statistics[i,:rho_liq_sat_n_points], r\"-\" => -1)\n",
    "    processed_data_statistics[i,:rho_liq_sp_n_points] = replace(processed_data_statistics[i,:rho_liq_sp_n_points], r\"-\" => -1)\n",
    "    processed_data_statistics[i,:rho_vap_n_points_outliers] = replace(processed_data_statistics[i,:rho_vap_n_points_outliers], r\"-\" => -1)\n",
    "\n",
    "end\n",
    "\n",
    "processed_data_statistics.Name = String.(processed_data_statistics.Name)\n",
    "processed_data_statistics.CAS = String15.(processed_data_statistics.CAS)\n",
    "processed_data_statistics.molarweight = Float64.(processed_data_statistics.molarweight)\n",
    "processed_data_statistics.p_sat_AAD = Float64.(processed_data_statistics.p_sat_AAD)\n",
    "processed_data_statistics.rho_liq_AAD = Float64.(processed_data_statistics.rho_liq_AAD)\n",
    "\n",
    "processed_data_statistics.p_sat_AAD_outliers = parse.(Float64, processed_data_statistics.p_sat_AAD_outliers)\n",
    "processed_data_statistics.rho_liq_sat_AAD = parse.(Float64, processed_data_statistics.rho_liq_sat_AAD)\n",
    "processed_data_statistics.rho_liq_sp_AAD = parse.(Float64, processed_data_statistics.rho_liq_sp_AAD)\n",
    "processed_data_statistics.rho_vap_AAD_outliers = parse.(Float64, processed_data_statistics.rho_vap_AAD_outliers)\n",
    "\n",
    "processed_data_statistics.p_sat_n_points = Int64.(processed_data_statistics.p_sat_n_points)\n",
    "processed_data_statistics.rho_liq_n_points = Int64.(processed_data_statistics.rho_liq_n_points)\n",
    "\n",
    "processed_data_statistics.p_sat_n_points_outliers = parse.(Int64, processed_data_statistics.p_sat_n_points_outliers)\n",
    "processed_data_statistics.rho_liq_sat_n_points = parse.(Int64, processed_data_statistics.rho_liq_sat_n_points)\n",
    "processed_data_statistics.rho_liq_sp_n_points = parse.(Int64, processed_data_statistics.rho_liq_sp_n_points)\n",
    "processed_data_statistics.rho_vap_n_points_outliers = parse.(Int64, processed_data_statistics.rho_vap_n_points_outliers)\n",
    "\n",
    "processed_data_statistics ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and structure Esper et al. SAFT parameter data\n",
    "raw_data_parameters = CSV.read(\"SI_pcp-saft_parameters.csv\",DataFrame,header=1) ;\n",
    "fieldnames(typeof(raw_data_parameters))\n",
    "#display(names(df)[1:20]) ;\n",
    "writedlm(\"out.txt\", names(raw_data_parameters), ' ') ;\n",
    "\n",
    "replace!(raw_data_parameters.mu, missing => 0) ;\n",
    "replace!(raw_data_parameters.kappa_ab, missing => 0) ;\n",
    "replace!(raw_data_parameters.epsilon_k_ab, missing => 0) ;\n",
    "\n",
    "raw_data_parameters.mu = Float64.(raw_data_parameters.mu)\n",
    "raw_data_parameters.kappa_ab = Float64.(raw_data_parameters.kappa_ab)\n",
    "raw_data_parameters.epsilon_k_ab = Float64.(raw_data_parameters.epsilon_k_ab) ;\n",
    "raw_data_parameters = sort(raw_data_parameters, :molarweight) \n",
    "\n",
    "raw_data_parameters = filter(row -> row.common_name != \"cis-2-butene\", raw_data_parameters)\n",
    "raw_data_parameters = filter(row -> row.common_name != \"(cis/trans)-2-butene\", raw_data_parameters)\n",
    "raw_data_parameters = filter(row -> row.common_name != \"cis-2-pentene\", raw_data_parameters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = nrow(raw_data_parameters)\n",
    "processed_data = DataFrame(\n",
    "    common_name = fill(missing, num_rows),\n",
    "    iupac_name = fill(missing, num_rows),\n",
    "    CAS = fill(missing,num_rows),\n",
    "    inchi = fill(missing,num_rows),\n",
    "    canonical_SMILES = fill(missing,num_rows),\n",
    "    isomeric_SMILES = fill(missing, num_rows), \n",
    "    family = fill(missing, num_rows),\n",
    "    Mw = fill(missing, num_rows),\n",
    "    segment = fill(missing, num_rows),\n",
    "    sigma = fill(missing, num_rows),\n",
    "    epsilon = fill(missing, num_rows),\n",
    "    dipole = fill(missing, num_rows),\n",
    "    kappa_ab = fill(missing, num_rows),\n",
    "    epsilon_k_ab = fill(missing, num_rows),\n",
    "    na = fill(missing, num_rows),\n",
    "    nb = fill(missing, num_rows),\n",
    "    expt_p_sat_T_min = fill(missing, num_rows),\n",
    "    expt_p_sat_T_max = fill(missing, num_rows),\n",
    "    expt_density_T_min = fill(missing, num_rows),\n",
    "    expt_density_T_max = fill(missing, num_rows),\n",
    "    interaction = fill(missing,num_rows),\n",
    "    bounds_violation = fill(missing,num_rows),\n",
    "    source = fill(missing, num_rows)\n",
    ") ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.common_name = raw_data_parameters.common_name\n",
    "processed_data.iupac_name = raw_data_parameters.iupac_name\n",
    "processed_data.CAS = raw_data_parameters.cas\n",
    "processed_data.inchi = raw_data_parameters.inchi\n",
    "processed_data.canonical_SMILES = raw_data_parameters.canonical_smiles\n",
    "processed_data.Mw = raw_data_parameters.molarweight\n",
    "processed_data.isomeric_SMILES = raw_data_parameters.isomeric_smiles\n",
    "processed_data.family = raw_data_parameters.family\n",
    "processed_data.segment = raw_data_parameters.m\n",
    "processed_data.sigma = raw_data_parameters.sigma\n",
    "processed_data.epsilon = raw_data_parameters.epsilon_k\n",
    "processed_data.dipole = raw_data_parameters.mu\n",
    "processed_data.kappa_ab = raw_data_parameters.kappa_ab\n",
    "processed_data.epsilon_k_ab = raw_data_parameters.epsilon_k_ab\n",
    "processed_data.na = raw_data_parameters.na\n",
    "processed_data.nb = raw_data_parameters.nb\n",
    "processed_data.expt_p_sat_T_min = raw_data_parameters.t_min_psat\n",
    "processed_data.expt_p_sat_T_max = raw_data_parameters.t_max_psat\n",
    "processed_data.expt_density_T_min = raw_data_parameters.t_min_density\n",
    "processed_data.expt_density_T_max = raw_data_parameters.t_max_density\n",
    "processed_data.interaction = raw_data_parameters.opt\n",
    "processed_data.bounds_violation = raw_data_parameters.bounds_violation\n",
    "processed_data[!, :source] .= \"10.1021/acs.iecr.3c02255\" ;\n",
    "\n",
    "species_names = processed_data.common_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = nrow(processed_data)\n",
    "training_data = DataFrame(\n",
    "    common_name = fill(missing, num_rows),\n",
    "    iupac_name = fill(missing, num_rows),\n",
    "    CAS = fill(missing,num_rows),\n",
    "    inchi = fill(missing,num_rows),\n",
    "    isomeric_SMILES = fill(missing, num_rows), \n",
    "    canonical_SMILES = fill(missing, num_rows), \n",
    "    family = fill(missing, num_rows),\n",
    "    Mw = fill(missing, num_rows),\n",
    "    interaction = fill(missing,num_rows),\n",
    "    source = fill(missing, num_rows),    \n",
    "    expt_p_sat_T_min = fill(0,num_rows),\n",
    "    expt_p_sat_T_max = fill(0,num_rows),\n",
    "    expt_density_T_min = fill(0,num_rows),\n",
    "    expt_density_T_max = fill(0,num_rows),\n",
    "    \n",
    "    p_sat_AAD = fill(0.0,num_rows),\n",
    "    p_sat_AAD_outliers = fill(0.0,num_rows),\n",
    "    rho_liq_AAD = fill(0.0,num_rows),\n",
    "    rho_liq_sat_AAD = fill(0.0,num_rows),\n",
    "    rho_liq_sp_AAD = fill(0.0,num_rows),\n",
    "    rho_vap_AAD_outliers = fill(0.0,num_rows),\n",
    "\n",
    "    p_sat_n_points = fill(0,num_rows),\n",
    "    p_sat_n_points_outliers = fill(0,num_rows),\n",
    "    rho_liq_n_points = fill(0,num_rows),\n",
    "    rho_liq_sat_n_points = fill(0,num_rows),\n",
    "    rho_liq_sp_n_points = fill(0,num_rows),\n",
    "    rho_vap_n_points_outliers = fill(0,num_rows),\n",
    ") ;\n",
    "\n",
    "training_data.common_name = processed_data.common_name\n",
    "training_data.iupac_name = processed_data.iupac_name\n",
    "training_data.CAS = processed_data.CAS\n",
    "training_data.inchi = processed_data.inchi\n",
    "training_data.isomeric_SMILES = processed_data.isomeric_SMILES\n",
    "training_data.canonical_SMILES = processed_data.canonical_SMILES\n",
    "training_data.family = processed_data.family\n",
    "training_data.Mw = processed_data.Mw\n",
    "training_data.interaction = processed_data.interaction\n",
    "training_data.source = processed_data.source \n",
    "\n",
    "training_data.expt_p_sat_T_min = processed_data.expt_p_sat_T_min ;\n",
    "training_data.expt_p_sat_T_max = processed_data.expt_p_sat_T_max ;\n",
    "training_data.expt_density_T_min = processed_data.expt_density_T_min ;\n",
    "training_data.expt_density_T_max = processed_data.expt_density_T_min ;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell generates data for all ~1800 species in Esper et al.\n",
    "# num_rows = nrow(processed_data)\n",
    "\n",
    "# n = 50\n",
    "\n",
    "# for i in species_names\n",
    "\n",
    "#     row_number = findall(processed_data.species .== i)[1]\n",
    "#     println(row_number,\" \",i)\n",
    "\n",
    "#     model = PPCSAFT(i) ;\n",
    "#     critical_props = crit_pure(model)\n",
    "\n",
    "#     temp_range = collect(range(0.5*critical_props[1],critical_props[1],n)) ;\n",
    "#     sat_props = [saturation_pressure(model,temp_range[i]) for i ∈ 1:n] ;\n",
    "\n",
    "#     sat_pressures = [sat_props[i][1] for i ∈ 1:n] ;\n",
    "#     sat_vols_liq = [sat_props[i][2] for i ∈ 1:n] ;\n",
    "#     sat_vols_vap = [sat_props[i][3] for i ∈ 1:n] ;\n",
    "\n",
    "#     for i in 1:length(critical_props)\n",
    "#         training_data[row_number, 7 + i] = critical_props[i]\n",
    "#     end\n",
    "\n",
    "#     training_data[row_number,:sat_temperatures_K] = temp_range\n",
    "#     training_data[row_number,:sat_pressures_MPa] = sat_pressures\n",
    "#     training_data[row_number,:sat_volumes_liq_m3_per_mol] = sat_vols_liq\n",
    "#     training_data[row_number,:sat_volumes_vap_m3_per_mol] = sat_vols_vap\n",
    "\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add statistics to training data dataframe\n",
    "for i = 1:nrow(training_data)\n",
    "    \n",
    "    cas_lookup = training_data[i,:CAS]\n",
    "    index_in_processed_data_statistics = findfirst(processed_data_statistics.CAS .== cas_lookup)\n",
    "\n",
    "    training_data[i,:p_sat_AAD] = processed_data_statistics[index_in_processed_data_statistics,:p_sat_AAD]\n",
    "    training_data[i,:p_sat_AAD_outliers] = processed_data_statistics[index_in_processed_data_statistics,:p_sat_AAD_outliers]\n",
    "    training_data[i,:rho_liq_AAD] = processed_data_statistics[index_in_processed_data_statistics,:rho_liq_AAD]\n",
    "    training_data[i,:rho_liq_sat_AAD] = processed_data_statistics[index_in_processed_data_statistics,:rho_liq_sat_AAD]\n",
    "    training_data[i,:rho_liq_sp_AAD] = processed_data_statistics[index_in_processed_data_statistics,:rho_liq_sp_AAD]\n",
    "    training_data[i,:rho_vap_AAD_outliers] = processed_data_statistics[index_in_processed_data_statistics,:rho_vap_AAD_outliers]\n",
    "\n",
    "    training_data[i,:p_sat_n_points] = processed_data_statistics[index_in_processed_data_statistics,:p_sat_n_points]\n",
    "    training_data[i,:p_sat_n_points_outliers] = processed_data_statistics[index_in_processed_data_statistics,:p_sat_n_points_outliers]\n",
    "    training_data[i,:rho_liq_n_points] = processed_data_statistics[index_in_processed_data_statistics,:rho_liq_n_points]\n",
    "    training_data[i,:rho_liq_sat_n_points] = processed_data_statistics[index_in_processed_data_statistics,:rho_liq_sat_n_points]\n",
    "    training_data[i,:rho_liq_sp_n_points] = processed_data_statistics[index_in_processed_data_statistics,:rho_liq_sp_n_points]\n",
    "    training_data[i,:rho_vap_n_points_outliers] = processed_data_statistics[index_in_processed_data_statistics,:rho_vap_n_points_outliers]\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data storage\n",
    "# CSV.write(\"training_data.csv\", training_data) ;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
